{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LangSmith を使った RAG アプリケーションの評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Ragas による合成テストデータの生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
    "    langchain-community==0.2.12 GitPython==3.1.43 \\\n",
    "    langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
    "    ragas==0.1.14 nest-asyncio==1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索対象のドキュメントのロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas による合成テストデータ生成の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【注意】既知のエラーについて\n",
    "\n",
    "以下のコードで gpt-4o を使用すると OpenAI API の Usage tier 次第で RateLimitError が発生することが報告されています。\n",
    "\n",
    "OpenAI API の Usage tier については公式ドキュメントの以下のページを参照してください。\n",
    "\n",
    "https://platform.openai.com/docs/guides/rate-limits/usage-tiers\n",
    "\n",
    "このエラーが発生した場合は、以下のどちらかの対応を実施してください。\n",
    "\n",
    "1. 同じ Tier でも gpt-4o よりレートリミットの高い gpt-4o-mini を使用する\n",
    "   - この場合、生成される合成テストデータの品質は低くなることが想定されます\n",
    "2. 課金などにより Tier を上げる\n",
    "   - Tier 2 で RateLimitError が発生しないことを確認済みです (2024 年 10 月 31 日時点)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    critic_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size=4,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith の Dataset の作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "dataset_name = \"agent-book\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "if client.has_dataset(dataset_name=dataset_name):\n",
    "    client.delete_dataset(dataset_name=dataset_name)\n",
    "\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成テストデータの保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "metadatas = []\n",
    "\n",
    "for testset_record in testset.test_data:\n",
    "    inputs.append(\n",
    "        {\n",
    "            \"question\": testset_record.question,\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"contexts\": testset_record.contexts,\n",
    "            \"ground_truth\": testset_record.ground_truth,\n",
    "        }\n",
    "    )\n",
    "    metadatas.append(\n",
    "        {\n",
    "            \"source\": testset_record.metadata[0][\"source\"],\n",
    "            \"evolution_type\": testset_record.evolution_type,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_examples(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    metadata=metadatas,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. LangSmith と Ragas を使ったオフライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタム Evaluator の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langsmith.schemas import Example, Run\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM\n",
    "\n",
    "\n",
    "class RagasMetricEvaluator:\n",
    "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
    "        self.metric = metric\n",
    "\n",
    "        # LLMとEmbeddingsをMetricに設定\n",
    "        if isinstance(self.metric, MetricWithLLM):\n",
    "            self.metric.llm = LangchainLLMWrapper(llm)\n",
    "        if isinstance(self.metric, MetricWithEmbeddings):\n",
    "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
    "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]\n",
    "\n",
    "        # Ragasの評価メトリクスのscoreメソッドでスコアを算出\n",
    "        score = self.metric.score(\n",
    "            {\n",
    "                \"question\": example.inputs[\"question\"],\n",
    "                \"answer\": run.outputs[\"answer\"],\n",
    "                \"contexts\": context_strs,\n",
    "                \"ground_truth\": example.outputs[\"ground_truth\"],\n",
    "            },\n",
    "        )\n",
    "        return {\"key\": self.metric.name, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import answer_relevancy, context_precision\n",
    "\n",
    "metrics = [context_precision, answer_relevancy]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "evaluators = [\n",
    "    RagasMetricEvaluator(metric, llm, embeddings).evaluate\n",
    "    for metric in metrics\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論の関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever,\n",
    "    }\n",
    ").assign(answer=prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
    "    question = inputs[\"question\"]\n",
    "    output = chain.invoke(question)\n",
    "    return {\n",
    "        \"contexts\": output[\"context\"],\n",
    "        \"answer\": output[\"answer\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オフライン評価の実装・実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    predict,\n",
    "    data=\"agent-book\",\n",
    "    evaluators=evaluators,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith を使ったオンライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示する関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langsmith import Client\n",
    "\n",
    "\n",
    "def display_feedback_buttons(run_id: UUID) -> None:\n",
    "    # GoodボタンとBadボタンを準備\n",
    "    good_button = widgets.Button(\n",
    "        description=\"Good\",\n",
    "        button_style=\"success\",\n",
    "        icon=\"thumbs-up\",\n",
    "    )\n",
    "    bad_button = widgets.Button(\n",
    "        description=\"Bad\",\n",
    "        button_style=\"danger\",\n",
    "        icon=\"thumbs-down\",\n",
    "    )\n",
    "\n",
    "    # クリックされた際に実行される関数を定義\n",
    "    def on_button_clicked(button: widgets.Button) -> None:\n",
    "        if button == good_button:\n",
    "            score = 1\n",
    "        elif button == bad_button:\n",
    "            score = 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown button: {button}\")\n",
    "\n",
    "        client = Client()\n",
    "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)\n",
    "        print(\"フィードバックを送信しました\")\n",
    "\n",
    "    # ボタンがクリックされた際にon_button_clicked関数を実行\n",
    "    good_button.on_click(on_button_clicked)\n",
    "    bad_button.on_click(on_button_clicked)\n",
    "\n",
    "    # ボタンを表示\n",
    "    display(good_button, bad_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tracers.context import collect_runs\n",
    "\n",
    "# LangSmithのトレースのID(Run ID)を取得するため、collect_runs関数を使用\n",
    "with collect_runs() as runs_cb:\n",
    "    output = chain.invoke(\"LangChainの概要を教えて\")\n",
    "    print(output[\"answer\"])\n",
    "    run_id = runs_cb.traced_runs[0].id\n",
    "\n",
    "display_feedback_buttons(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
